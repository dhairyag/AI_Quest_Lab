<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Processing App</title>
    <link rel="stylesheet" href="{{ url_for('static', path='/styles.css') }}">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;500;600;700&family=Poppins:wght@300;400;500&family=Source+Code+Pro&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <img src="{{ url_for('static', path='images/logo.svg') }}" alt="Logo" style="width: 25%;">
        <p style="margin-bottom: 20px;">Web app designed to visualize preprocessing and augmentation results on text, audio, image, and 3D geometry.</p>
        <div class="main-content">
            <div class="sidebar">
                <div class="upload-section">
                    <h2>Upload Data</h2>
                    <form id="upload-form">
                        <select id="data-type">
                            <option value="text">Text</option>
                            <option value="audio">Audio</option>
                            <option value="image">Image</option>
                            <option value="3d_geometry">3D Geometry</option>
                        </select>
                        <input type="file" id="file-input" name="file" 
                            accept=".txt,.wav,.mp3,.ogg,.png,.jpg,.jpeg,.off,audio/*,image/*,text/plain" 
                            required>
                        <button type="submit">Upload</button>
                    </form>
                </div>
                <div class="processing-section">
                    <h2>Process Data</h2>
                    <div class="preprocessing">
                        <h3>Preprocessing</h3>
                        <div id="preprocessing-options"></div>
                    </div>
                    <div class="augmentation">
                        <h3>Augmentation</h3>
                        <div id="augmentation-options"></div>
                    </div>
                    <button id="apply-btn">Apply</button>
                </div>
            </div>
            <div class="data-display">
                <div class="data-box">
                    <h3>Original Data</h3>
                    <div class="data-content">
                        <div id="originalData"></div>
                    </div>
                </div>
                <div class="data-box">
                    <h3>Processed Result</h3>
                    <div id="appliedEffect" class="applied-effect"></div>
                    <div class="data-content">
                        <div id="processedData"></div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <script>
        let uploadedData = null;

        document.getElementById('upload-form').addEventListener('submit', async (e) => {
            e.preventDefault();
            const dataType = document.getElementById('data-type').value;
            const fileInput = document.getElementById('file-input');
            
            // Validate file type
            const validTypes = {
                'text': ['text/plain', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'],
                'audio': ['audio/wav', 'audio/mpeg', 'audio/ogg'],
                'image': ['image/png', 'image/jpeg', 'image/gif'],
                '3d_geometry': ['application/octet-stream']
            };
            
            if (!fileInput.files[0]) {
                alert('Please select a file');
                return;
            }
            
            // Check file extension
            const fileName = fileInput.files[0].name.toLowerCase();
            const fileExt = fileName.substring(fileName.lastIndexOf('.'));
            const validExts = {
                'text': ['.txt', '.doc', '.docx'],
                'audio': ['.wav', '.mp3', '.ogg'],
                'image': ['.png', '.jpg', '.jpeg', '.gif'],
                '3d_geometry': ['.off']
            };
            
            if (!validExts[dataType].includes(fileExt) && !validTypes[dataType].includes(fileInput.files[0].type)) {
                alert(`Invalid file type. Please select a valid ${dataType} file.`);
                fileInput.value = ''; // Clear the file input
                return;
            }
            
            // Continue with the upload if validation passes
            const submitButton = e.target.querySelector('button');
            submitButton.disabled = true;
            submitButton.textContent = 'Uploading...';
            
            try {
                const formData = new FormData();
                const file = fileInput.files[0];
                formData.append('file', file);
                
                console.log('Uploading file:', {
                    name: file.name,
                    type: file.type,
                    size: file.size,
                    dataType: dataType
                });
                
                const response = await fetch(`/upload/${dataType}`, {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Upload failed: ${errorText}`);
                }
                
                const result = await response.json();
                console.log('Upload response:', result);
                
                uploadedData = result;
                displayResult(result);
                showProcessingOptions(dataType);
            } catch (error) {
                console.error('Error:', error);
                alert(`Upload failed: ${error.message}`);
            } finally {
                // Reset loading state
                submitButton.disabled = false;
                submitButton.textContent = 'Upload';
            }
        });

        function showProcessingOptions(dataType) {
            const preprocessingOptions = document.getElementById('preprocessing-options');
            const augmentationOptions = document.getElementById('augmentation-options');

            // Clear previous options
            preprocessingOptions.innerHTML = '';
            augmentationOptions.innerHTML = '';

            // Add preprocessing options based on data type
            const preProcessingSteps = getPreprocessingSteps(dataType);
            preProcessingSteps.forEach(step => {
                const radio = createRadio(step, 'processing');
                preprocessingOptions.appendChild(radio);
            });

            // Add augmentation options based on data type
            const augmentationTechniques = getAugmentationTechniques(dataType);
            augmentationTechniques.forEach(technique => {
                const radio = createRadio(technique, 'processing');
                augmentationOptions.appendChild(radio);
            });

            // Show apply button
            document.getElementById('apply-btn').style.display = 'inline-block';
        }

        function createRadio(label, name) {
            const div = document.createElement('div');
            const radio = document.createElement('input');
            radio.type = 'radio';
            radio.id = `${name}-${label}`;
            radio.name = name;
            radio.value = label;

            const labelElement = document.createElement('label');
            labelElement.htmlFor = radio.id;
            
            // Create tooltip icon
            const tooltipIcon = document.createElement('span');
            tooltipIcon.className = 'tooltip-icon';
            tooltipIcon.textContent = 'ⓘ';  // Info icon
            
            // Get the current data type from the select element
            const dataType = document.getElementById('data-type').value;
            
            // Add tooltips based on the processing type and label
            const tooltips = {
                // Text preprocessing tooltips
                'Tokenize': 'Tokenizes text using a pre-trained BERT tokenizer',
                'Pad': 'Pads or truncates a sequence of tokens to a fixed length',
                'Embed': 'Maps tokens to vectors using a pre-trained BERT model',
                'Remove Punctuation': 'Removes all punctuation marks from the text',
                
                // Image preprocessing tooltips
                'Resize': 'Resizes image to a target size (224x224 by default)',
                'Normalize': {
                    'image': 'Normalizes image using ImageNet statistics (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])',
                    'audio': 'Normalizes audio using peak or RMS normalization methods to standardize volume levels',
                    '3d_geometry': 'Scales vertices to fit within a unit sphere and centers at origin'
                },
                'Grayscale': 'Converts image to grayscale',
                'ML Preprocess': 'Applies standard ML preprocessing pipeline including resize, normalization, and optional grayscale conversion',
                
                // Audio preprocessing tooltips
                'MFCC': 'Calculates Mel-frequency cepstral coefficients (MFCC) features',
                'Resample': 'Resamples audio to a specified target sample rate (16000Hz by default)',
                'Trim Silence': 'Trims leading and trailing silence from audio',
                
                // 3D geometry preprocessing tooltips
                'Centering': 'Centers the geometry at origin by subtracting mean vertex position',

                // Augmentation tooltips
                'Synonym Replacement': 'Replaces random words with their synonyms',
                'Random Insertion': 'Inserts random words from the text at random positions',
                'Flip': 'Applies random horizontal flip to the image',
                'Rotate': 'Applies random rotation to the image (up to 30 degrees)',
                'Add Noise': {
                    'image': 'Applies color jittering to adjust brightness, contrast, saturation, and hue',
                    'audio': 'Adds random background noise to audio samples (noise factor: 0.005)',
                    '3d_geometry': 'Adds random noise to 3D geometry vertices (noise factor: 0.02)'
                },
                'Time Stretch': 'Applies time stretching to audio samples (rate=1.2)',
                'Pitch Shift': 'Applies pitch shifting to audio samples (2 steps)',
                'Random Rotation': 'Applies random rotation to 3D geometry vertices around all axes',
                'Random Scaling': 'Applies random scaling (0.75-1.25) to 3D geometry vertices'
            };

            // Get the tooltip text based on label and data type
            let tooltipText;
            if (tooltips[label] && typeof tooltips[label] === 'object') {
                // For labels that have different descriptions based on data type
                tooltipText = tooltips[label][dataType];
            } else {
                // For labels that have a single description
                tooltipText = tooltips[label];
            }

            // Set the tooltip on the icon
            tooltipIcon.title = tooltipText || `Apply ${label}`;

            // Create a text node for the label
            const labelText = document.createTextNode(label);

            div.appendChild(radio);
            labelElement.appendChild(tooltipIcon);
            labelElement.appendChild(labelText);
            div.appendChild(labelElement);
            return div;
        }

        function getPreprocessingSteps(dataType) {
            // Return preprocessing steps based on data type
            switch (dataType) {
                case 'text':
                    return ['Pad', 'Remove Punctuation', 'Tokenize', 'Embed'];
                case 'image':
                    return ['Resize', 'Normalize', 'Grayscale', 'ML Preprocess'];
                case 'audio':
                    return ['Normalize', 'Trim Silence', 'Resample', 'MFCC'];
                case '3d_geometry':
                    return ['Normalize', 'Centering'];
                default:
                    return [];
            }
        }

        function getAugmentationTechniques(dataType) {
            // Return augmentation techniques based on data type
            switch (dataType) {
                case 'text':
                    return ['Synonym Replacement', 'Random Insertion'];
                case 'image':
                    return ['Rotate', 'Flip', 'Add Noise'];
                case 'audio':
                    return ['Time Stretch', 'Pitch Shift', 'Add Noise'];
                case '3d_geometry':
                    return ['Random Rotation', 'Random Scaling', 'Add Noise'];
                default:
                    return [];
            }
        }

        document.getElementById('apply-btn').addEventListener('click', async () => {
            if (!uploadedData) return;

            const selectedOption = document.querySelector('input[name="processing"]:checked');
            if (!selectedOption) {
                console.error('No processing option selected');
                return;
            }
            const dataType = uploadedData.data_type;
            const isPreprocessing = getPreprocessingSteps(dataType).includes(selectedOption.value);

            // Prepare the request data based on data type
            let requestData;
            if (dataType === 'audio') {
                // For audio, send the original data directly
                const audioData = uploadedData.sample.original;
                console.log('Original audio data:', audioData);
                
                // Make sure we're sending the complete audio data structure
                if (!audioData || !audioData.audio_data) {
                    console.error('Invalid audio data structure:', audioData);
                    alert('Invalid audio data structure');
                    return;
                }
                
                // Send the complete audio data object
                requestData = {
                    data: audioData,  // This contains type, audio_data, and sample_rate
                    [isPreprocessing ? 'preprocessing_steps' : 'augmentation_techniques']: [selectedOption.value]
                };
                
                console.log('Sending audio request:', requestData);
            } else if (dataType === '3d_geometry') {
                // Fix: Get the complete geometry data from the original upload
                const geometryData = {
                    vertices: uploadedData.sample.original.vertices,  // Access vertices from the correct path
                    faces: uploadedData.sample.original.faces        // Access faces from the correct path
                };
                
                requestData = {
                    data: geometryData,
                    [isPreprocessing ? 'preprocessing_steps' : 'augmentation_techniques']: [selectedOption.value]
                };
                
                console.log('Sending geometry data:', requestData); // Add logging
            } else if (dataType === 'text') {
                // New handling for 'text' data type
                const textData = uploadedData.sample.original;
                if (!textData) {
                    console.error('Invalid text data structure:', textData);
                    alert('Invalid text data structure');
                    return;
                }

                requestData = {
                    data: textData,
                    preprocessing_steps: isPreprocessing ? [selectedOption.value] : [],
                    augmentation_techniques: !isPreprocessing ? [selectedOption.value] : []
                };
            } else if (dataType === 'image') {
                // New handling for 'image' data type
                const imageData = uploadedData.sample.original;
                if (!imageData) {
                    console.error('Invalid image data structure:', imageData);
                    alert('Invalid image data structure');
                    return;
                }

                requestData = {
                    data: imageData,
                    preprocessing_steps: isPreprocessing ? [selectedOption.value] : [],
                    augmentation_techniques: !isPreprocessing ? [selectedOption.value] : []
                };
            }

            try {
                const endpoint = isPreprocessing ? 'preprocess' : 'augment';
                const response = await fetch(`/${endpoint}/${dataType}`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(requestData),
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    console.error('Server response:', errorText);
                    throw new Error(`HTTP error! status: ${response.status}, message: ${errorText}`);
                }
                
                const result = await response.json();
                console.log('Processing response:', result);
                
                // Update display
                displayResult({
                    sample: {
                        original: uploadedData.sample.original,
                        processed: result.sample.processed
                    },
                    data_type: dataType,
                    appliedEffect: `${isPreprocessing ? 'Preprocessing' : 'Augmentation'} - ${selectedOption.value}`
                });
            } catch (error) {
                console.error('Error:', error);
                alert(`Processing failed: ${error.message}`);
            }
        });

        function displayResult(data) {
            const originalDataDiv = document.getElementById('originalData');
            const processedDataDiv = document.getElementById('processedData');
            const appliedEffectDiv = document.getElementById('appliedEffect');
            
            // Display the applied effect if any
            if (data.appliedEffect) {
                appliedEffectDiv.textContent = data.appliedEffect;
            }
            
            // Display original data
            if (data.sample && data.sample.original) {
                displayData(originalDataDiv, data.sample.original, data.data_type);
            }

            // Display processed data
            if (data.sample && data.sample.processed) {
                displayData(processedDataDiv, data.sample.processed, data.data_type);
            } else {
                processedDataDiv.textContent = "No processing applied yet.";
            }
        }

        function displayData(container, data, dataType) {
            container.innerHTML = '';
            
            if (dataType === '3d_geometry') {
                const wrapper = document.createElement('div');
                wrapper.className = 'geometry-wrapper';
                
                // Display the 2D projection image
                const img = document.createElement('img');
                img.src = data.image;
                img.className = 'geometry-projection';
                
                // Store the complete geometry data in the container's dataset
                wrapper.dataset.vertices = JSON.stringify(data.vertices);
                wrapper.dataset.faces = JSON.stringify(data.faces);
                
                // Add vertex count information
                const info = document.createElement('div');
                info.className = 'geometry-info';
                info.textContent = `Number of vertices: ${data.vertices_count}`;
                
                wrapper.appendChild(img);
                wrapper.appendChild(info);
                container.appendChild(wrapper);
            } else if (dataType === 'audio') {
                const audioContainer = document.createElement('div');
                audioContainer.className = 'audio-controls';
                
                // Check if it's a spectrogram or audio
                if (data.type === 'spectrogram' && data.is_mfcc) {
                    console.log('Displaying MFCC spectrogram');
                    // Display MFCC spectrogram image
                    const img = document.createElement('img');
                    img.src = `data:image/png;base64,${data.image_data}`;
                    img.className = 'spectrogram-image';
                    
                    const description = document.createElement('div');
                    description.className = 'spectrogram-description';
                    description.textContent = data.description || 'MFCC Spectrogram';
                    
                    // Add sample rate information if available
                    if (data.sample_rate) {
                        const sampleRateDiv = document.createElement('div');
                        sampleRateDiv.className = 'sample-rate';
                        sampleRateDiv.textContent = `Original Sample Rate: ${data.sample_rate} Hz`;
                        audioContainer.appendChild(sampleRateDiv);
                    }
                    
                    audioContainer.appendChild(description);
                    audioContainer.appendChild(img);
                } else if (data.type === 'audio') {
                    // Regular audio display
                    const audio = document.createElement('audio');
                    audio.controls = true;
                    
                    if (data.audio_data) {
                        audio.src = `data:audio/wav;base64,${data.audio_data}`;
                    } else {
                        console.error('No audio data available');
                        audioContainer.innerHTML = '<div class="error-message">No audio data available</div>';
                        container.appendChild(audioContainer);
                        return;
                    }
                    
                    // Add sample rate if available
                    if (data.sample_rate) {
                        const sampleRateDiv = document.createElement('div');
                        sampleRateDiv.className = 'sample-rate';
                        sampleRateDiv.textContent = `Sample Rate: ${data.sample_rate} Hz`;
                        audioContainer.appendChild(sampleRateDiv);
                    }
                    
                    audioContainer.appendChild(audio);
                } else {
                    console.error('Unknown audio data type:', data.type);
                    audioContainer.innerHTML = '<div class="error-message">Unknown audio data format</div>';
                }
                
                container.appendChild(audioContainer);
            } else if (dataType === 'text') {
                const pre = document.createElement('pre');
                pre.textContent = data;
                container.appendChild(pre);
            } else if (dataType === 'image') {
                const wrapper = document.createElement('div');
                wrapper.className = 'image-wrapper';
                
                const img = document.createElement('img');
                img.src = `data:image/png;base64,${data}`;
                img.className = 'img-fluid';
                
                img.onload = function() {
                    const dimensions = document.createElement('div');
                    dimensions.className = 'image-dimensions';
                    dimensions.textContent = `Image Size: ${this.naturalWidth} × ${this.naturalHeight}px`;
                    wrapper.appendChild(dimensions);
                };
                
                wrapper.appendChild(img);
                container.appendChild(wrapper);
            }
        }

        function displaySample(response) {
            const textDisplay = document.getElementById('text-sample');
            const imageDisplay = document.getElementById('image-sample');
            
            // Hide both displays initially
            textDisplay.style.display = 'none';
            imageDisplay.style.display = 'none';

            if (response.data_type === 'text') {
                textDisplay.style.display = 'block';
                document.getElementById('original-text').textContent = response.sample.original;
                document.getElementById('processed-text').textContent = response.sample.processed || 'Not processed yet';
            } 
            else if (response.data_type === 'image') {
                imageDisplay.style.display = 'block';
                document.getElementById('original-image').src = `data:image/jpeg;base64,${response.sample.original}`;
                if (response.sample.processed) {
                    document.getElementById('processed-image').src = `data:image/jpeg;base64,${response.sample.processed}`;
                }
            }
        }

        // Use this function when handling the upload response
        async function handleUpload(formData) {
            const response = await fetch('/upload/text', {
                method: 'POST',
                body: formData
            });
            const data = await response.json();
            displaySample(data);
        }

        document.getElementById('data-type').addEventListener('change', function() {
            const fileInput = document.getElementById('file-input');
            switch (this.value) {
                case 'text':
                    fileInput.accept = '.txt,.doc,.docx,text/plain,application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document';
                    break;
                case 'audio':
                    fileInput.accept = '.wav,.mp3,.ogg,audio/wav,audio/mpeg,audio/ogg';
                    break;
                case 'image':
                    fileInput.accept = '.png,.jpg,.jpeg,.gif,image/png,image/jpeg,image/gif';
                    break;
                case '3d_geometry':
                    fileInput.accept = '.off';
                    break;
            }
        });

        // Trigger change event on page load to set initial accept attribute
        document.getElementById('data-type').dispatchEvent(new Event('change'));
    </script>
</body>
</html>
